{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0117696-636e-482b-9790-c4c3b93e49ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "481aafaa-a31e-4811-bec4-e0f7b59a3494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fix the structure of the `transcripts` datasets like the first ones\n",
    "\n",
    "# Read the text file\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove any line breaks within a single sentence\n",
    "text = re.sub(r'(?<=[a-z]),?-?\\n(?=[a-z])', ' ', text, flags=re.IGNORECASE)\n",
    "\n",
    "# Split the text into lines based on the end of a sentence\n",
    "lines = re.split(r'(?<=[.!?]) +(?=[A-Z])', text)\n",
    "\n",
    "# Preprocess the transcript data\n",
    "output_lines = []\n",
    "for line in lines:\n",
    "    if re.match(r'^\\d+\\.\\d+', line) and output_lines:\n",
    "        output_lines.append('\\n' + line)\n",
    "    else:\n",
    "        output_lines.append(line)\n",
    "\n",
    "# Update the original text file with the preprocessed data\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'w') as f:\n",
    "    f.write('\\n'.join(output_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90f2d22e-5101-42dd-b0b4-4348b44c24d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read the first dataset containing the YouTube chapters into a pandas DataFrame:\n",
    "chapters = []\n",
    "with open('Dataset/timestamps/Episode-5.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        columns = line.strip().split(' ')\n",
    "        time = columns[0]\n",
    "        chapter = ' '.join(columns[1:])\n",
    "        chapters.append([time, chapter])\n",
    "\n",
    "chapters_df = pd.DataFrame(chapters, columns=['time', 'chapter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29a90a3a-0f7b-4665-bd3f-c12191ca0a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read the second dataset containing the YouTube transcripts into a pandas DataFrame:\n",
    "transcripts = []\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        columns = line.strip().split(' ')\n",
    "        second = columns[0]\n",
    "        text = ' '.join(columns[1:])\n",
    "        transcripts.append([second, text])\n",
    "\n",
    "transcripts_df = pd.DataFrame(transcripts, columns=['second', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d4b270c-0b2f-477a-8e25-83ffd9082725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Aggregate the datasets\n",
    "dataset = chapters_df\n",
    "\n",
    "## Add the transcript column \n",
    "dataset['transcript'] = ''\n",
    "\n",
    "temp_text = \"\"\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    # Set the start time of the chapter | Convert it to seconds\n",
    "    start_time = row['time']\n",
    "    start_time_object = datetime.datetime.strptime(start_time, \"%H:%M:%S\")\n",
    "    start_time_seconds = start_time_object.hour * 3600 + start_time_object.minute * 60 + start_time_object.second\n",
    "\n",
    "    # Get the next row\n",
    "    if index < len(dataset)-1:\n",
    "        end_time = dataset.iloc[index+1]['time']\n",
    "    else:\n",
    "        next_time = None\n",
    "        next_text = None\n",
    "        break\n",
    "        \n",
    "    # Set the end time of the chapter | Convert it to seconds\n",
    "    end_time_object = datetime.datetime.strptime(end_time, \"%H:%M:%S\")\n",
    "    end_time_seconds = end_time_object.hour * 3600 + end_time_object.minute * 60 + end_time_object.second\n",
    "\n",
    "    # convert the 'time' column from string to float\n",
    "    for row in\n",
    "    try :\n",
    "        transcripts_df['second'] = transcripts_df['second'].astype(float)\n",
    "    except:\n",
    "        temp_text = transcripts_df['second'] + transcripts_df['text']\n",
    "        print(temp_text)\n",
    "        print('----------------------------------------------------------')\n",
    "        continue\n",
    "    # select the rows with time between start_time and end_time, and concatenate the text values\n",
    "    selected_text = transcripts_df.loc[(transcripts_df['second'] >= start_time_seconds) & (transcripts_df['second'] <= end_time_seconds), 'text'].str.cat(sep=' ')\n",
    "    \n",
    "    dataset.loc[index, 'transcript'] = str(temp_text) + str(selected_text)\n",
    "    temp_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34145c76-7f2f-456a-a15e-ba8f0f5fefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the aggregated dataset as a csv file\n",
    "dataset.to_csv('Dataset/Aggregated Dataset/Episode_5.csv', index=False, columns=['time', 'chapter', 'transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c3343-8014-424d-a28c-c8fad2119b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
