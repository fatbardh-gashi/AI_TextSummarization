{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8cabad-d86c-4526-b026-0e316346cb07",
   "metadata": {},
   "source": [
    "# Text Summarization of Andrew Huberman Podcast Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc94252-fb4a-4d7b-9583-a8797c273527",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49ba2f06-b195-46db-ac17-17aaa322ca3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import spacy\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21256fe-f8c3-4020-b4c3-c62612e1b660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess & Aggregate the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "481aafaa-a31e-4811-bec4-e0f7b59a3494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fix the structure of the `transcripts` datasets like the first ones\n",
    "\n",
    "# Read the text file\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Remove any line breaks within a single sentence\n",
    "text = re.sub(r'(?<=[a-z]),?-?\\n(?=[a-z])', ' ', text, flags=re.IGNORECASE)\n",
    "\n",
    "# Split the text into lines based on the end of a sentence\n",
    "lines = re.split(r'(?<=[.!?]) +(?=[A-Z])', text)\n",
    "\n",
    "# Preprocess the transcript data\n",
    "output_lines = []\n",
    "for line in lines:\n",
    "    if re.match(r'^\\d+\\.\\d+', line) and output_lines:\n",
    "        output_lines.append('\\n' + line)\n",
    "    else:\n",
    "        output_lines.append(line)\n",
    "\n",
    "# Update the original text file with the preprocessed data\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'w') as f:\n",
    "    f.write('\\n'.join(output_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90f2d22e-5101-42dd-b0b4-4348b44c24d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read the first dataset containing the YouTube chapters into a pandas DataFrame:\n",
    "chapters = []\n",
    "with open('Dataset/timestamps/Episode-5.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        columns = line.strip().split(' ')\n",
    "        time = columns[0]\n",
    "        chapter = ' '.join(columns[1:])\n",
    "        chapters.append([time, chapter])\n",
    "\n",
    "chapters_df = pd.DataFrame(chapters, columns=['time', 'chapter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29a90a3a-0f7b-4665-bd3f-c12191ca0a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read the second dataset containing the YouTube transcripts into a pandas DataFrame:\n",
    "transcripts = []\n",
    "with open('Dataset/transcripts/Episode-5.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        columns = line.strip().split(' ')\n",
    "        second = columns[0]\n",
    "        text = ' '.join(columns[1:])\n",
    "        transcripts.append([second, text])\n",
    "\n",
    "transcripts_df = pd.DataFrame(transcripts, columns=['second', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d4b270c-0b2f-477a-8e25-83ffd9082725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Aggregate the datasets\n",
    "dataset = chapters_df\n",
    "\n",
    "## Add the transcript column \n",
    "dataset['transcript'] = ''\n",
    "\n",
    "temp_text = \"\"\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    # Set the start time of the chapter | Convert it to seconds\n",
    "    start_time = row['time']\n",
    "    start_time_object = datetime.datetime.strptime(start_time, \"%H:%M:%S\")\n",
    "    start_time_seconds = start_time_object.hour * 3600 + start_time_object.minute * 60 + start_time_object.second\n",
    "\n",
    "    # Get the next row\n",
    "    if index < len(dataset)-1:\n",
    "        end_time = dataset.iloc[index+1]['time']\n",
    "    else:\n",
    "        next_time = None\n",
    "        next_text = None\n",
    "        break\n",
    "        \n",
    "    # Set the end time of the chapter | Convert it to seconds\n",
    "    end_time_object = datetime.datetime.strptime(end_time, \"%H:%M:%S\")\n",
    "    end_time_seconds = end_time_object.hour * 3600 + end_time_object.minute * 60 + end_time_object.second\n",
    "\n",
    "    # convert the 'time' column from string to float\n",
    "    for row in\n",
    "    try :\n",
    "        transcripts_df['second'] = transcripts_df['second'].astype(float)\n",
    "    except:\n",
    "        temp_text = transcripts_df['second'] + transcripts_df['text']\n",
    "        print(temp_text)\n",
    "        print('----------------------------------------------------------')\n",
    "        continue\n",
    "    # select the rows with time between start_time and end_time, and concatenate the text values\n",
    "    selected_text = transcripts_df.loc[(transcripts_df['second'] >= start_time_seconds) & (transcripts_df['second'] <= end_time_seconds), 'text'].str.cat(sep=' ')\n",
    "    \n",
    "    dataset.loc[index, 'transcript'] = str(temp_text) + str(selected_text)\n",
    "    temp_text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5ef5d-8787-4f89-968c-f5b4b64967d4",
   "metadata": {},
   "source": [
    "## Save the aggregated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34145c76-7f2f-456a-a15e-ba8f0f5fefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the aggregated dataset as a csv file\n",
    "dataset.to_csv('Dataset/Aggregated Dataset/Episode_5.csv', index=False, columns=['time', 'chapter', 'transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd257a31-a9cb-4060-b372-18a562cc6593",
   "metadata": {},
   "source": [
    "## Build the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "843af487-fdec-49df-b5df-0ca6a04850e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Read one of the datasets\n",
    "aggregated_dataset = pd.read_csv('Dataset/Aggregated Dataset/Episode_1_Summary_Included.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9c781c00-749e-45a4-90c1-f0a176a8d3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove non-alphabetic characters (Data Cleaning)\n",
    "def text_strip(column):\n",
    "\n",
    "    for row in column:\n",
    "        row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove _ if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(__+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove - if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(--+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove ~ if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(~~+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove + if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(\\+\\++)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove . if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(\\.\\.+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove the characters - <>()|&©ø\"',;?~*!\n",
    "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove mailto:\n",
    "        row = re.sub(\"(mailto:)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove \\x9* in text\n",
    "        row = re.sub(r\"(\\\\x9\\d)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Replace INC nums to INC_NUM\n",
    "        row = re.sub(\"([iI][nN][cC]\\d+)\", \"INC_NUM\", str(row)).lower()\n",
    "\n",
    "        # Replace CM# and CHG# to CM_NUM\n",
    "        row = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", \"CM_NUM\", str(row)).lower()\n",
    "\n",
    "        # Remove punctuations at the end of a word\n",
    "        row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Replace any url to only the domain name\n",
    "        try:\n",
    "            url = re.search(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", repl_url, str(row))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Remove multiple spaces\n",
    "        row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove the single character hanging between any two spaces\n",
    "        row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ab6d7de8-d9ca-44c4-a2e3-b742819db8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>chapter</th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>Endurance: Benefits, Mechanics &amp; Breathing</td>\n",
       "      <td>welcome to the huberman Lab podcast where we d...</td>\n",
       "      <td>In this episode of the Huberman Lab podcast, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0:07:30</td>\n",
       "      <td>Tool: “Exercise Snacks”</td>\n",
       "      <td>huberman Lab podcast is now partnered with mom...</td>\n",
       "      <td>The Huberman Lab podcast has partnered with Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0:14:21</td>\n",
       "      <td>Momentous, Levels, LMNT</td>\n",
       "      <td>inflammatory responses so let's talk about the...</td>\n",
       "      <td>The text discusses the different types of head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0:18:01</td>\n",
       "      <td>Endurance Categories</td>\n",
       "      <td>splinter into a particular uh you know skin ar...</td>\n",
       "      <td>The text discusses the different causes of inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0:22:16</td>\n",
       "      <td>Fat Loss &amp; Respiration; Carbon Cycles &amp; Storag...</td>\n",
       "      <td>experience pain whether or not it's a pin pric...</td>\n",
       "      <td>The text explains that pain is neural in origi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     time                                            chapter   \n",
       "0           1  0:00:00         Endurance: Benefits, Mechanics & Breathing  \\\n",
       "1           2  0:07:30                            Tool: “Exercise Snacks”   \n",
       "2           3  0:14:21                            Momentous, Levels, LMNT   \n",
       "3           4  0:18:01                               Endurance Categories   \n",
       "4           5  0:22:16  Fat Loss & Respiration; Carbon Cycles & Storag...   \n",
       "\n",
       "                                          transcript   \n",
       "0  welcome to the huberman Lab podcast where we d...  \\\n",
       "1  huberman Lab podcast is now partnered with mom...   \n",
       "2  inflammatory responses so let's talk about the...   \n",
       "3  splinter into a particular uh you know skin ar...   \n",
       "4  experience pain whether or not it's a pin pric...   \n",
       "\n",
       "                                             summary  \n",
       "0  In this episode of the Huberman Lab podcast, P...  \n",
       "1  The Huberman Lab podcast has partnered with Mo...  \n",
       "2  The text discusses the different types of head...  \n",
       "3  The text discusses the different causes of inf...  \n",
       "4  The text explains that pain is neural in origi...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d639c87-127c-4477-a740-bd02e62d5356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_text = text_strip(aggregated_dataset['transcript'])\n",
    "processed_summary = text_strip(aggregated_dataset['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7241f5f-cd4d-4dc1-9e7f-e772e2638d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the data as batches using the pipe() method provided by spaCy.\n",
    "## This ensures that all pieces of text and summaries possess the string data type.\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) \n",
    "\n",
    "# Process text as batches and yield Doc objects in order\n",
    "text = [str(doc) for doc in nlp.pipe(processed_text, batch_size=5000)]\n",
    "\n",
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(processed_summary, batch_size=5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "382667b2-bef3-47e7-b589-81b948938734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Store the text and summary lists in pandas objects.\n",
    "\n",
    "aggregated_dataset['cleaned_text'] = pd.Series(text)\n",
    "aggregated_dataset['cleaned_summary'] = pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72233472-98ac-43fe-8b6d-9ebf8d4ed0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>chapter</th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>Endurance: Benefits, Mechanics &amp; Breathing</td>\n",
       "      <td>welcome to the huberman Lab podcast where we d...</td>\n",
       "      <td>In this episode of the Huberman Lab podcast, P...</td>\n",
       "      <td>welcome to the huberman lab podcast where we d...</td>\n",
       "      <td>_START_ in this episode of the huberman lab po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0:07:30</td>\n",
       "      <td>Tool: “Exercise Snacks”</td>\n",
       "      <td>huberman Lab podcast is now partnered with mom...</td>\n",
       "      <td>The Huberman Lab podcast has partnered with Mo...</td>\n",
       "      <td>huberman lab podcast is now partnered with mom...</td>\n",
       "      <td>_START_ the huberman lab podcast has partnered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0:14:21</td>\n",
       "      <td>Momentous, Levels, LMNT</td>\n",
       "      <td>inflammatory responses so let's talk about the...</td>\n",
       "      <td>The text discusses the different types of head...</td>\n",
       "      <td>inflammatory responses so let talk about the n...</td>\n",
       "      <td>_START_ the text discusses the different types...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0:18:01</td>\n",
       "      <td>Endurance Categories</td>\n",
       "      <td>splinter into a particular uh you know skin ar...</td>\n",
       "      <td>The text discusses the different causes of inf...</td>\n",
       "      <td>splinter into particular uh you know skin area...</td>\n",
       "      <td>_START_ the text discusses the different cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0:22:16</td>\n",
       "      <td>Fat Loss &amp; Respiration; Carbon Cycles &amp; Storag...</td>\n",
       "      <td>experience pain whether or not it's a pin pric...</td>\n",
       "      <td>The text explains that pain is neural in origi...</td>\n",
       "      <td>experience pain whether or not it a pin prick ...</td>\n",
       "      <td>_START_ the text explains that pain is neural ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     time                                            chapter   \n",
       "0           1  0:00:00         Endurance: Benefits, Mechanics & Breathing  \\\n",
       "1           2  0:07:30                            Tool: “Exercise Snacks”   \n",
       "2           3  0:14:21                            Momentous, Levels, LMNT   \n",
       "3           4  0:18:01                               Endurance Categories   \n",
       "4           5  0:22:16  Fat Loss & Respiration; Carbon Cycles & Storag...   \n",
       "\n",
       "                                          transcript   \n",
       "0  welcome to the huberman Lab podcast where we d...  \\\n",
       "1  huberman Lab podcast is now partnered with mom...   \n",
       "2  inflammatory responses so let's talk about the...   \n",
       "3  splinter into a particular uh you know skin ar...   \n",
       "4  experience pain whether or not it's a pin pric...   \n",
       "\n",
       "                                             summary   \n",
       "0  In this episode of the Huberman Lab podcast, P...  \\\n",
       "1  The Huberman Lab podcast has partnered with Mo...   \n",
       "2  The text discusses the different types of head...   \n",
       "3  The text discusses the different causes of inf...   \n",
       "4  The text explains that pain is neural in origi...   \n",
       "\n",
       "                                        cleaned_text   \n",
       "0  welcome to the huberman lab podcast where we d...  \\\n",
       "1  huberman lab podcast is now partnered with mom...   \n",
       "2  inflammatory responses so let talk about the n...   \n",
       "3  splinter into particular uh you know skin area...   \n",
       "4  experience pain whether or not it a pin prick ...   \n",
       "\n",
       "                                     cleaned_summary  \n",
       "0  _START_ in this episode of the huberman lab po...  \n",
       "1  _START_ the huberman lab podcast has partnered...  \n",
       "2  _START_ the text discusses the different types...  \n",
       "3  _START_ the text discusses the different cause...  \n",
       "4  _START_ the text explains that pain is neural ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33497f7d-243b-4c8d-b647-8dcfbef33c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a graph to determine the frequency ranges tied to the lengths of text and summary, \n",
    "## i.e., determine the range of length of words where the maximum number of texts and summaries fall into.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
